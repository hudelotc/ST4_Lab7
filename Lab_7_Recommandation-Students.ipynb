{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C2za_H4hdJW"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "\n",
    "# Lab 7 : Personnalisation : Systèmes de recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hh-yuZxVhdJZ"
   },
   "source": [
    "Ce LAB a pour objectif de vous familiariser avec le problème de la recommandation par la réalisation d'un système de recommandation de films.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGlCzY7ihdJa"
   },
   "source": [
    "### Avant propos : un bref rappel du Filtrage Collaboratif\n",
    "\n",
    "Le problème de la recommandation vise à prédire des scores de pertinence personnalisés à l’utilisateur pour un item, objet non vu. Différentes approches existent : filtrage collaboratif, basées sur le contenu, basées sur la connaissances, ...  (voir le cours 7)\n",
    "\n",
    "Dans ce Lab on s'intéressera au Filtrage collaboratif. L'idée est de prendre en compte les relations de similarité entre les utilisateurs et les éléments. En d'autres termes, la similarité entre éléments est déterminée en prenant en\n",
    "compte les notes des utilisateurs ayant jugés ces éléments.\n",
    "\n",
    "<img src=\"./Figures/recommandationcollaborative.png\" width=\"350\" height=\"350\" />\n",
    "\n",
    "Deux types de filtrage collaboratif :\n",
    "\n",
    "- **Approche par voisinnage (memory-based)** : cette approche calcule la prédiction d'un item $i$ pour un utilisateur $x$ en se basant sur les plus proches voisins de $x$ (i.e. ceux dont l'ensemble de notations est similaire à l'ensemble des notation de $x$). \n",
    "\n",
    "- **Approche par modèles (model-based)** : cette approche cherche à predire le score d'un item $i$ pour un utilisateur $x$, sur la base des items qui sont similaires à $i$. Donc, l'estimation de la note pour l’élément se fait à partir des notes des éléments de $x$ similaires à $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE 1 : Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note : </b> un exercice sur un fichier pdf séparé est disponible sur EDUNAO. Il vous permettra de réviser plus simplement les concepts du cours.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2RLGi6fhdKC"
   },
   "source": [
    "## PARTIE 2 : Applicaton au corpus MovieLens\n",
    "\n",
    "Dans cette partie nous travaillerons sur la base du corpus [MOVIELENS dataset](https://grouplens.org/datasets/movielens/) qui contient les jugements de films d'un ensemble d'utilisateurs ainsi que des informations sur les utilisateurs et sur les films. L'objectif de cette partie est de mettre en place un système de recommandation de films à partir de ce corpus. \n",
    "Il s'agira par exemple de pouvoir répondre à la question suivante : *quels sont les films pouvant plaire à une personne étant donné la connaissance sur cette personne (e.g. les autres films qu'elle a aimé ou les utilisateurs ressemblant à cette personne) ?* \n",
    "\n",
    "Pour ce travail, il est conseillé de travailler avec le [MovieLens 100K Dataset](https://grouplens.org/datasets/movielens/100k/) et de tester ensuite votre approche sur les datasets de  taille plus conséquente :\n",
    " + MovieLens 1M Dataset (1M de notes sur 4000 films par 6000 utilisateurs), disponible [ici](https://grouplens.org/datasets/movielens/1m/)\n",
    " + MovieLens 10M Dataset (10M de notes sur 10 000 films par 72000 utilisateurs, disponible [ici](https://grouplens.org/datasets/movielens/10m/)\n",
    " \n",
    "Pour répondre aux différentes questions nous allons faire appel à la bibliothque Pandas, que nous vous proposons de découvrir dans ce qui suit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBzxD1r7hdKF"
   },
   "source": [
    "### Un petit aperçu de Pandas\n",
    "\n",
    "Avant de commencer, nous vous proposons de découvir la bibliothèque `Pandas` à l'aide d'un petit tuto qui se trouve [ici](./TutoPanda/Lab_5_Recom_Tuto_Pandas.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMWC2ZZQhdKH",
    "outputId": "0622f354-a512-4ba3-bdea-d004c745cb4c"
   },
   "outputs": [],
   "source": [
    "#Si vous avez déjà fait le tuto il n'est pas nécessaire de refaire l'installation\n",
    "\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4lwSQUDhdKT"
   },
   "source": [
    "### Etude du corpus\n",
    "\n",
    "Une des premières choses à faire est de prendre connaissance de ce corpus et de calculer quelques informations statistiques sur ce corpus. A l'aide des bibliothèques [pandas](https://pandas.pydata.org/), et [numpy](https://www.numpy.org),  répondez aux questions qui vont suivre concernant le corpus. Mais avant cela, nous allons introduire quelques éléments descriptifs utiles sur le corpus.\n",
    "\n",
    "Le corpus MOVIELENS est disponible [ici](https://grouplens.org/datasets/movielens/100k/).  Plus précisemment, ce corpus est constitué des fichiers suivants :\n",
    "\n",
    "+ Le fichier [u.data](./Data/ml-100k/u.data) : regroupe l'ensemble des données : 100000 notations par 943 utilisateurs sur 1682 items. Chaque utilisateur  a noté au moins 20 films.  Cette table contient:  \n",
    "\n",
    "               user id | item id | rating | timestamp.           \n",
    "          \n",
    "  les utilisateurs et les items sont numérotés à partir de  1 et les données sont aléatoirement ordonées.  \n",
    "  \n",
    "              \n",
    "+ Le fichier [u.user](./Data/ml-100k/u.user) : information démographique sur les utiliisateurs. Il contient: \n",
    "                         \n",
    "              user id | age | gender | occupation | zip code\n",
    "                         \n",
    "                            \n",
    "+ Le fichier [u.item](./Data/ml-100k/u.item) : contient les informations sur les items (films) : \n",
    "              \n",
    "              movie id | movie title | release date | video release date |\n",
    "              IMDb URL | unknown | Action | Adventure | Animation |\n",
    "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\n",
    "              Thriller | War | Western |\n",
    "              \n",
    "\n",
    "\n",
    "**Le code suivant permet d'extraire le contenu de ces fichiers.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgWnltoihdKU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#column headers for the dataset\n",
    "\n",
    "data_cols = ['user_id','item_id','rating','timestamp']\n",
    "\n",
    "#items' table\n",
    "item_cols = ['movie id','movie title','release date',\n",
    "'video release date','IMDb URL','unknown','Action',\n",
    "'Adventure','Animation','Childrens','Comedy','Crime',\n",
    "'Documentary','Drama','Fantasy','Film-Noir','Horror',\n",
    "'Musical','Mystery','Romance ','Sci-Fi','Thriller',\n",
    "'War' ,'Western']\n",
    "\n",
    "\n",
    "#users' table\n",
    "user_cols = ['user id','age','gender','occupation',\n",
    "'zip code']\n",
    "\n",
    "#importing the data files onto dataframes\n",
    "\n",
    "users = pd.read_csv('./Data/ml-100k/u.user', sep='|',names=user_cols, encoding='latin-1')\n",
    "item = pd.read_csv('./Data/ml-100k/u.item', sep='|',names=item_cols, encoding='latin-1')\n",
    "data = pd.read_csv('./Data/ml-100k/u.data', sep='\\t',names=data_cols, encoding='latin-1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIoE9YzUhdKW",
    "outputId": "5dc3a514-0e74-4b4a-ce04-3caa34dbe420"
   },
   "outputs": [],
   "source": [
    "#printing the head of these dataframes\n",
    "\n",
    "print(\"User information\")\n",
    "print(users.head()) # it will print only the head. To have the whole table remove .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJ48ldcrhdKb",
    "outputId": "e6a133d1-2ab1-4db4-c434-6698be727881"
   },
   "outputs": [],
   "source": [
    "print(\"Item information\")\n",
    "print(item.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfdAS_cZhdKg",
    "outputId": "cc38d42c-7b55-4e18-c86e-6a499e782812"
   },
   "outputs": [],
   "source": [
    "print(\"Data information\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-kDWQ20hdKm"
   },
   "source": [
    "**1- Quel est le nombre de films et d'utilisateurs du corpus ?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncTDlieNhdKn"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "\n",
    "nb_users = # to complete\n",
    "nb_items = #to complete\n",
    "\n",
    "print(\"Number of users : \", nb_users)\n",
    "print(\"Number of movies : \", nb_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result1.png\" width=\"250\" height=\"250\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01a3RaTFhdKq"
   },
   "source": [
    "**2- Contruire la matrice d'utilité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWnfb4lahdKs"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "\n",
    "movie_matrix= #to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected result (here only the head)**\n",
    "\n",
    "<img src=\"./Figures/result2.png\" width=\"450\" height=\"450\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9rMb7dzhdKv"
   },
   "source": [
    "**3- Quelle est la note moyenne de chaque film ?** \n",
    "\n",
    "Indication: on peut utiliser la fonction `groupby()` de Pandas. Quelqeus exemples [ici](https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm). Sinon ne pas oublier de se reférer à la documentation officielle de Pandas [ici](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibyYaFRdhdKv"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "\n",
    "ratings = #To compelete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected result (here only the head)**\n",
    "\n",
    "<img src=\"./Figures/result3.png\" width=\"100\" height=\"100\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-k-fteghdKy"
   },
   "source": [
    "**4- Visualisation de la distribution des notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning: </b> if you did not install yet matplotlip, excute in a separate cell `!pip install matplotlib` \n",
    "</div>\n",
    "\n",
    "\n",
    "Remarque : `%matplotlib`configure la bibliothèque que vous allez utiliser pour dessiner le graphique. Elle effectue donc un certain nombre de traitements pour préparer l'affichage du graphique. Elle est souvent utilisée avec l'argument `inline`, qui indique que l'on va utiliser la bibliothèque intégrée à Notebook. \n",
    "\n",
    "Pour la fonction `hist()` des exemples [ici](https://www.science-emergence.com/Articles/Simple-histogramme-avec-matplotlib/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Op3WiLpIhdK2"
   },
   "outputs": [],
   "source": [
    "# Attention ces instructions ne peuvent être executées sans la réalisation de la question 3. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ratings['rating'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result4.png\" width=\"200\" height=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzQF3CRfhdK5"
   },
   "source": [
    " **5- Quel est le nombre de notes pour chaque film ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOGzS6TdhdK5"
   },
   "outputs": [],
   "source": [
    "ratings['number_of_ratings'] = # To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected result (head only)**\n",
    "\n",
    "<img src=\"./Figures/result5.png\" width=\"200\" height=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6- Visualiser le nombre de notes pour chaque film (comme nous l'avons fait question 4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h3Rcdr_ghdK8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Système de recommandation\n",
    "\n",
    "### Préparation de l'évaluation\n",
    "\n",
    "Une première phase dans le problème de prédiction de la recommandation est de préparer l'étape évaluation de votre système de recommendationn en séparant l'ensemble de données en  un ensemble de test et en un ensemble d'apprentissage. \n",
    "\n",
    "<img src=\"./Figures/recommandationevaluation2.png\" width=\"250\" height=\"250\" />\n",
    "\n",
    "- L'ensemble d'apprentissage sera utilisé pour construire la matrice d'utilité, calculer le score de similarité et faire la prédiction. \n",
    "- L'ensemble de test sera utilisé dans la phase d'évaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning: </b> if you did not install yet sklearn, excute in a separate cell `!pip install sklearn`\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Séaprons nos données `data` en deux sous ensembles : un ensemble d'apprentissage et un ensemble de test. On prendra par exemple une taille d'ensemble de test de $0.25$**.\n",
    "\n",
    "Indication : on fera appel à la fonction `model_selection()` dont la documentation se trouve [ici](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VEuuoQ4hdK_"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "\n",
    "train_data, test_data = # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Taindata\\n\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testdata\\n\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igQk5XmfhdLC"
   },
   "source": [
    "### Approche par voisinage (user-item, Memory-based)\n",
    "\n",
    "Il s'agit d'implémenter la méthode de filtrage collaboratif par voisinage **user-item** en suivant les étapes qui suivent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EK9zAAlbhdLD"
   },
   "source": [
    "### Etape 1 : \n",
    "\n",
    "**a- Construire la matrice user-item à partir de l'ensemble des données. (Cela vous permettra de visualiser le contenu des données qui sont considérées pour l'apprentissage.)** \n",
    "\n",
    "Attention : on utilisera la matrice `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfXbO3fAhdLE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "movie_matrix = # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b- Constuire la matrice contenant que les notes ou les évaluations des différents items. On appelera cette matrice `train_data_matrix`. C'est cette matrice qui sera utilisée par la suite pour faire nos calculs de similarités et de prédictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data_matrix= #To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result_b.png\" width=\"150\" height=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfhU7P2mhdLH"
   },
   "source": [
    "**c- Construire la matrice de test contenant que les évalaution (ou les notations) des différents items. On appelara cette matrice `test_data_matrix`. C'est cette matrice qui sera utilisée par la suite dans la phase évaluation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZZhStbshdLH"
   },
   "outputs": [],
   "source": [
    "test_data_matrix =# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result_c.png\" width=\"150\" height=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUGDWIPZhdLK"
   },
   "source": [
    "### Etape 2 : Création et calcul d'une matrice de similarité entre utilisateurs. \n",
    "\n",
    "On utilisera dans un premier temps la mesure **cosinus** : \n",
    "\n",
    "$$sim(x,y) = cos (r_x,r_y) = \\frac{r_x.r_y}{||r_x||.||r_y||}$$\n",
    "\n",
    "\n",
    "(on pourra utiliser pour cela la méthode **pairwise\\_distances** de scikit-learn documentée [ici](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vs-WyEythdLL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "user_similarity= # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Conseil : </b> terminer en premier le travail avec la mesure cosinus. Une fois la fonction de prédiction mise en place et que celle-ci fonctionne vous pouvez revenir pour écrire la\n",
    "    fonction de similarité avec Pearson et la tester ensuite avec la fonction de prédiction. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oILyUMfohdLN"
   },
   "source": [
    "**Faire le même travail avec la mesure de corrélation de Pearson comme mesure de similarité entre les différents vecteurs de notes et définie comme, étant donnés deux utilisateurs $x$ et $y$ :**\n",
    "\n",
    "$$ sim(x,y) = \\frac{\\sum_{s \\in S_{xy}} (r_{xs} - \\overline{r_x})(r_{ys} - \\overline{r_y}) }{ \\sqrt{\\sum_{s \\in S_{xy}} (r_{xs} - \\overline{r_x})^2}   \\sqrt{\\sum_{s \\in S_{xy}} (r_{ys} - \\overline{r_y})^2}  }$$\n",
    "\n",
    "avec $\\overline{r_y}$ et  $\\overline{r_x}$ la notation moyenne de $x$ et $y$.\n",
    "\n",
    "Calculer cette métrique pour chaque paire d'utilisateurs dans la base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ4CF-PehdLP"
   },
   "source": [
    "**Remarque**: `pearsonr()` da la bibliothèque `stats` retourne un deux-tuple composé du coefficient de corrélation et de la p-valeur:\n",
    "\n",
    "Le coefficient de corrélation peut varier de -1 à +1. L'hypothèse nulle est que les deux variables ne sont pas corrélées. La valeur de $p$ est un nombre compris entre zéro et celui qui représente la probabilité que vos données se serait produites si l'hypothèse nulle était vraie.\n",
    "Pour plus de détails, voir http://www.eecs.qmul.ac.uk/~norman/blog_articles/p_values.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7Y-yzlghdLP",
    "outputId": "b45ca281-02a4-41bd-f102-6d5a93ac34b7"
   },
   "outputs": [],
   "source": [
    "#Exemple\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
    "b = np.arange(7)\n",
    "stats.pearsonr(a, b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47bomxpdhdLS"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6QZtYdIhdLV"
   },
   "source": [
    "### Etape 3 :  Construire la matrice de prédictions en utilisant la formule suivante.\n",
    "\n",
    "La note de l'utilisateur $x$ sur l'élément $i$ est calculée comme :\n",
    "\n",
    "$$ r_{xi} = \\overline{r_x} + \\frac{\\sum_{y \\in N} sim(x,y) (r_{yi} -\\overline{r_y})}{\\sum_{y \\in N} | sim(x,y)|}$$\n",
    "\n",
    "\n",
    "Avec: $\\overline{r}_x$ la note moyenne de l'utilisateur $x$ et $r_{yi}$ la note de l'utilisateur $y$ qui a jugé $i$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ecrire la fonction `predict(ratings, similarity, type='user')` qui prendra en entrée les évaluations, la matrice de similarités et un troisième argument qui est `type='user'`. Il est intéressant de le considérer pour pourvoir réutiliser la fonction dans l'approche par modèles en mettant `type='item'`.** \n",
    "\n",
    "**Encore une fois vous pouvez écrire simplement la fonction `predict(ratings, similarity)` qui retournera à la fin la matrice de prédictions des différents items pour les différents utilisateurs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DH0EDZJYhdLW"
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    \n",
    "    # TO COMPLETE\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzA-Yir1hdLY"
   },
   "source": [
    "### Etape 4 :  Evaluer votre prédiction avec la mesure RMSE (Root Mean Squared Error).\n",
    "\n",
    "\n",
    "$$\\sqrt{\\frac{1}{n} \\sum_{xi} (r_{xi} - r_{xi}^{*})^{2}}$$\n",
    "où, $r_{xi}^{*}$ correspond à la valeur prédite pour $r_{xi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAf-iPZhhdLZ"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse(prediction, ground_truth):\n",
    "    #To compelte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche par modèles : **item-item**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Conseil : </b>  à faire une fois la partie memory-based réalisée. \n",
    "</div>\n",
    "\n",
    "#### **Faire le même travail avec l'approche item-item. Il est possible  de réutiliser les fonctions implémentées précédemment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_5_Recommandation-Students.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
